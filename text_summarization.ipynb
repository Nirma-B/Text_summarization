{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: sumy in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: torch in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 246.6 kB/s eta 0:00:39\n",
      "   --- ------------------------------------ 0.8/10.0 MB 349.5 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.8/10.0 MB 349.5 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.8/10.0 MB 349.5 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 0.8/10.0 MB 349.5 kB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 337.7 kB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 337.7 kB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 337.7 kB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 337.7 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 325.7 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 325.7 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 325.7 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.0 MB 342.3 kB/s eta 0:00:25\n",
      "   ------ --------------------------------- 1.6/10.0 MB 342.3 kB/s eta 0:00:25\n",
      "   ------ --------------------------------- 1.6/10.0 MB 342.3 kB/s eta 0:00:25\n",
      "   ------- -------------------------------- 1.8/10.0 MB 358.2 kB/s eta 0:00:23\n",
      "   ------- -------------------------------- 1.8/10.0 MB 358.2 kB/s eta 0:00:23\n",
      "   -------- ------------------------------- 2.1/10.0 MB 374.0 kB/s eta 0:00:22\n",
      "   -------- ------------------------------- 2.1/10.0 MB 374.0 kB/s eta 0:00:22\n",
      "   -------- ------------------------------- 2.1/10.0 MB 374.0 kB/s eta 0:00:22\n",
      "   --------- ------------------------------ 2.4/10.0 MB 387.9 kB/s eta 0:00:20\n",
      "   --------- ------------------------------ 2.4/10.0 MB 387.9 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 402.6 kB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 422.5 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 422.5 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 3.1/10.0 MB 444.7 kB/s eta 0:00:16\n",
      "   ------------ --------------------------- 3.1/10.0 MB 444.7 kB/s eta 0:00:16\n",
      "   ------------- -------------------------- 3.4/10.0 MB 448.4 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.4/10.0 MB 448.4 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.4/10.0 MB 448.4 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.4/10.0 MB 448.4 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 3.4/10.0 MB 448.4 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 3.7/10.0 MB 426.0 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 3.7/10.0 MB 426.0 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 3.9/10.0 MB 428.6 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 3.9/10.0 MB 428.6 kB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 440.7 kB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 440.7 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 453.4 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 4.7/10.0 MB 463.7 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 4.7/10.0 MB 463.7 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 5.0/10.0 MB 475.6 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 5.2/10.0 MB 488.1 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 5.2/10.0 MB 488.1 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 498.6 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 508.4 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 508.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 6.0/10.0 MB 514.1 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 6.3/10.0 MB 522.8 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 6.6/10.0 MB 536.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 6.8/10.0 MB 549.0 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 562.1 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 572.0 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 572.0 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 7.6/10.0 MB 580.7 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 7.9/10.0 MB 591.1 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.1/10.0 MB 598.5 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 8.4/10.0 MB 606.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 615.7 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 622.0 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 631.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.2/10.0 MB 631.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 9.4/10.0 MB 638.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 646.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 646.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 646.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 636.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 636.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 636.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 636.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 599.1 kB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.29.2 pyyaml-6.0.2 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob transformers sumy nltk torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nirma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub_folders = os.listdir('BBC_News_Summary/News Articles')\n",
    "sub_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "News_Articles_Path = 'BBC_News_Summary/News Articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def reading_files(base_path, sub_folders):\n",
    "    articles = []\n",
    "    categories = []\n",
    "\n",
    "    for folder in sub_folders:\n",
    "        folder_path = os.path.join(base_path, folder)  # Full folder path\n",
    "        if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "            for file in os.listdir(folder_path):  # Iterate over files\n",
    "                file_path = os.path.join(folder_path, file)  # Full file path\n",
    "                if os.path.isfile(file_path):  # Ensure it's a file\n",
    "                    with open(file_path, 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                        articles.append(f.read().replace('\\n', ''))  # Store article content\n",
    "                        categories.append(folder)  # Store category name\n",
    "\n",
    "    return articles, categories\n",
    "\n",
    "# Define paths\n",
    "cwd = 'BBC_News_Summary/'\n",
    "News_Articles_Path = os.path.join(cwd, 'News Articles/')\n",
    "Summaries_Path = os.path.join(cwd, 'Summaries/')\n",
    "\n",
    "# Get list of category folders\n",
    "article_folders = os.listdir(News_Articles_Path)  # Categories in News Articles\n",
    "summary_folders = os.listdir(Summaries_Path)  # Categories in Summaries\n",
    "\n",
    "# Read articles and categories\n",
    "articles, categories = reading_files(News_Articles_Path, article_folders)\n",
    "\n",
    "# Print dataset size\n",
    "print(len(articles))  # Number of articles\n",
    "print(len(categories))  # Number of categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>tech</td>\n",
       "      <td>BT program to beat dialler scamsBT is introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>tech</td>\n",
       "      <td>Spam e-mails tempt net shoppersComputer users ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>tech</td>\n",
       "      <td>Be careful how you codeA new European directiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>tech</td>\n",
       "      <td>US cyber security chief resignsThe man making ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>tech</td>\n",
       "      <td>Losing yourself in online gamingOnline role pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                           Articles\n",
       "0     business  Ad sales boost Time Warner profitQuarterly pro...\n",
       "1     business  Dollar gains on Greenspan speechThe dollar has...\n",
       "2     business  Yukos unit buyer faces loan claimThe owners of...\n",
       "3     business  High fuel prices hit BA's profitsBritish Airwa...\n",
       "4     business  Pernod takeover talk lifts DomecqShares in UK ...\n",
       "...        ...                                                ...\n",
       "2220      tech  BT program to beat dialler scamsBT is introduc...\n",
       "2221      tech  Spam e-mails tempt net shoppersComputer users ...\n",
       "2222      tech  Be careful how you codeA new European directiv...\n",
       "2223      tech  US cyber security chief resignsThe man making ...\n",
       "2224      tech  Losing yourself in online gamingOnline role pl...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Category': categories, 'Articles': articles})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>high fuel prices hit ba's profitsbritish airwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                           Articles  \\\n",
       "0  business  Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1  business  Dollar gains on Greenspan speechThe dollar has...   \n",
       "2  business  Yukos unit buyer faces loan claimThe owners of...   \n",
       "3  business  High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4  business  Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "\n",
       "                                               Lower  \n",
       "0  ad sales boost time warner profitquarterly pro...  \n",
       "1  dollar gains on greenspan speechthe dollar has...  \n",
       "2  yukos unit buyer faces loan claimthe owners of...  \n",
       "3  high fuel prices hit ba's profitsbritish airwa...  \n",
       "4  pernod takeover talk lifts domecqshares in uk ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Lower'] = df['Articles'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Punctuations_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>high fuel prices hit ba's profitsbritish airwa...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                           Articles  \\\n",
       "0  business  Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1  business  Dollar gains on Greenspan speechThe dollar has...   \n",
       "2  business  Yukos unit buyer faces loan claimThe owners of...   \n",
       "3  business  High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4  business  Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "\n",
       "                                               Lower  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit ba's profitsbritish airwa...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                                Punctuations_removal  \n",
       "0  ad sales boost time warner profitquarterly pro...  \n",
       "1  dollar gains on greenspan speechthe dollar has...  \n",
       "2  yukos unit buyer faces loan claimthe owners of...  \n",
       "3  high fuel prices hit bas profitsbritish airway...  \n",
       "4  pernod takeover talk lifts domecqshares in uk ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Punctuations_removal'] = df['Lower'].str.replace('[^\\w\\s]','', regex = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Punctuations_removal</th>\n",
       "      <th>Special_Characters_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>high fuel prices hit ba's profitsbritish airwa...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                           Articles  \\\n",
       "0  business  Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1  business  Dollar gains on Greenspan speechThe dollar has...   \n",
       "2  business  Yukos unit buyer faces loan claimThe owners of...   \n",
       "3  business  High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4  business  Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "\n",
       "                                               Lower  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit ba's profitsbritish airwa...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                                Punctuations_removal  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit bas profitsbritish airway...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                          Special_Characters_removal  \n",
       "0  ad sales boost time warner profitquarterly pro...  \n",
       "1  dollar gains on greenspan speechthe dollar has...  \n",
       "2  yukos unit buyer faces loan claimthe owners of...  \n",
       "3  high fuel prices hit bas profitsbritish airway...  \n",
       "4  pernod takeover talk lifts domecqshares in uk ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "df['Special_Characters_removal'] = df['Punctuations_removal'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", ' ', x))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Punctuations_removal</th>\n",
       "      <th>Special_Characters_removal</th>\n",
       "      <th>Stopwords_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "      <td>ad sales boost time warner profitquarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains on greenspan speechthe dollar has...</td>\n",
       "      <td>dollar gains greenspan speechthe dollar hit hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners of...</td>\n",
       "      <td>yukos unit buyer faces loan claimthe owners em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>high fuel prices hit ba's profitsbritish airwa...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "      <td>high fuel prices hit bas profitsbritish airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares in uk ...</td>\n",
       "      <td>pernod takeover talk lifts domecqshares uk dri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                           Articles  \\\n",
       "0  business  Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1  business  Dollar gains on Greenspan speechThe dollar has...   \n",
       "2  business  Yukos unit buyer faces loan claimThe owners of...   \n",
       "3  business  High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4  business  Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "\n",
       "                                               Lower  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit ba's profitsbritish airwa...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                                Punctuations_removal  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit bas profitsbritish airway...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                          Special_Characters_removal  \\\n",
       "0  ad sales boost time warner profitquarterly pro...   \n",
       "1  dollar gains on greenspan speechthe dollar has...   \n",
       "2  yukos unit buyer faces loan claimthe owners of...   \n",
       "3  high fuel prices hit bas profitsbritish airway...   \n",
       "4  pernod takeover talk lifts domecqshares in uk ...   \n",
       "\n",
       "                                   Stopwords_removal  \n",
       "0  ad sales boost time warner profitquarterly pro...  \n",
       "1  dollar gains greenspan speechthe dollar hit hi...  \n",
       "2  yukos unit buyer faces loan claimthe owners em...  \n",
       "3  high fuel prices hit bas profitsbritish airway...  \n",
       "4  pernod takeover talk lifts domecqshares uk dri...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['Stopwords_removal'] = df['Special_Characters_removal'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Tokens: ['ad', 'sales', 'boost', 'time', 'warner', 'profitquarterly', 'profits', 'us', 'media', 'giant']\n",
      "Row 2 Tokens: ['dollar', 'gains', 'greenspan', 'speechthe', 'dollar', 'hit', 'highest', 'level', 'euro', 'almost']\n",
      "Row 3 Tokens: ['yukos', 'unit', 'buyer', 'faces', 'loan', 'claimthe', 'owners', 'embattled', 'russian', 'oil']\n",
      "Row 4 Tokens: ['high', 'fuel', 'prices', 'hit', 'bas', 'profitsbritish', 'airways', 'blamed', 'high', 'fuel']\n",
      "Row 5 Tokens: ['pernod', 'takeover', 'talk', 'lifts', 'domecqshares', 'uk', 'drinks', 'food', 'firm', 'allied']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "df['Tokenization'] = df['Stopwords_removal'].apply(lambda x: word_tokenize(str(x)))\n",
    "\n",
    "# Print tokenized words for the first 5 rows\n",
    "for i in range(5):  \n",
    "    print(f\"Row {i+1} Tokens:\", df['Tokenization'].iloc[i][:10])  # Print first 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 Stemmed: ['ad', 'sale', 'boost', 'time', 'warner', 'profitquarterli', 'profit', 'us', 'media', 'giant']\n",
      "Row 2 Stemmed: ['dollar', 'gain', 'greenspan', 'speechth', 'dollar', 'hit', 'highest', 'level', 'euro', 'almost']\n",
      "Row 3 Stemmed: ['yuko', 'unit', 'buyer', 'face', 'loan', 'claimth', 'owner', 'embattl', 'russian', 'oil']\n",
      "Row 4 Stemmed: ['high', 'fuel', 'price', 'hit', 'ba', 'profitsbritish', 'airway', 'blame', 'high', 'fuel']\n",
      "Row 5 Stemmed: ['pernod', 'takeov', 'talk', 'lift', 'domecqshar', 'uk', 'drink', 'food', 'firm', 'alli']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "df['Stemming'] = df['Tokenization'].apply(lambda x: \" \".join([st.stem(word) for word in x]))\n",
    "\n",
    "# Print stemmed words for the first 5 rows\n",
    "for i in range(5):  \n",
    "    print(f\"Row {i+1} Stemmed:\", df['Stemming'].iloc[i].split()[:10])  # Print first 10 stemmed words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ad sale boost time warner profitquarterli profit u medium giant timewarn jump 76 113bn 600m three month decemb 639m yearearlierth firm one biggest investor googl benefit sale highspe internet connect higher advert sale timewarn said fourth quarter sale rose 2 111bn 109bn profit buoy oneoff gain offset profit dip warner bro less user aoltim warner said friday own 8 searchengin googl internet busi aol mix fortun lost 464000 subscrib fourth quarter profit lower preced three quarter howev compani said aol underli profit except item rose 8 back stronger internet advertis revenu hope increas subscrib offer onlin servic free timewarn internet custom tri sign aol exist custom highspe broadband timewarn also restat 2000 2003 result follow probe u secur exchang commiss sec close concludingtim warner fourth quarter profit slightli better analyst expect film divis saw profit slump 27 284m help boxoffic flop alexand catwoman sharp contrast yearearli third final film lord ring trilog boost result fullyear timewarn post profit 336bn 27 2003 perform revenu grew 64 4209bn financi perform strong meet exceed fullyear object greatli enhanc flexibl chairman chief execut richard parson said 2005 timewarn project oper earn growth around 5 also expect higher revenu wider profit marginstimewarn restat account part effort resolv inquiri aol u market regul alreadi offer pay 300m settl charg deal review sec compani said unabl estim amount need set asid legal reserv previous set 500m intend adjust way account deal german music publish bertelsmann purchas stake aol europ report advertis revenu book sale stake aol europ loss valu stake\n",
       "Name: Lemmatization, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "df['Lemmatization'] = df['Stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  display(df['Lemmatization'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Summaries_Path = 'D:\\Python\\Text_summarization\\BBC_News_Summary\\Summaries'\n",
    "\n",
    "sub_folders = os.listdir('D:\\Python\\Text_summarization\\BBC_News_Summary\\Summaries')\n",
    "sub_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def reading_summary_files(Summaries_Path, sub_folders):\n",
    "    summaries = []\n",
    "    cat = []\n",
    "\n",
    "\n",
    "    for folder in sub_folders:\n",
    "        summary_paths = glob.glob(os.path.join(Summaries_Path, folder, '*.txt'))\n",
    "    \n",
    "        for i in range(len(summary_paths)):\n",
    "          cat.append(folder)\n",
    "\n",
    "          with open(summary_paths[i], mode = 'r', encoding = 'ISO-8859-1') as f:\n",
    "            summaries.append(f.read())\n",
    "                \n",
    "    return summaries, cat\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summaries, cat = reading_summary_files(Summaries_Path, sub_folders)\n",
    "print(len(summaries))\n",
    "print(len(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>tech</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>tech</td>\n",
       "      <td>A third of them read unsolicited junk e-mail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>tech</td>\n",
       "      <td>This goes to the heart of the European project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>tech</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>tech</td>\n",
       "      <td>He says that in the world of online gaming suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Summary\n",
       "0     business  TimeWarner said fourth quarter sales rose 2% t...\n",
       "1     business  The dollar has hit its highest level against t...\n",
       "2     business  Yukos' owner Menatep Group says it will ask Ro...\n",
       "3     business  Rod Eddington, BA's chief executive, said the ...\n",
       "4     business  Pernod has reduced the debt it took on to fund...\n",
       "...        ...                                                ...\n",
       "2220      tech  BT is introducing two initiatives to help beat...\n",
       "2221      tech  A third of them read unsolicited junk e-mail a...\n",
       "2222      tech  This goes to the heart of the European project...\n",
       "2223      tech  Amit Yoran was director of the National Cyber ...\n",
       "2224      tech  He says that in the world of online gaming suc...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df_summary = pd.DataFrame({'Category': cat, 'Summary': summaries})\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.Time Warner's fourth quarter profits were slightly better than analysts' expectations.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Summary']=df_summary['Summary']\n",
    "df['Summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scamsBT is introduc...</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppersComputer users ...</td>\n",
       "      <td>A third of them read unsolicited junk e-mail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you codeA new European directiv...</td>\n",
       "      <td>This goes to the heart of the European project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resignsThe man making ...</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gamingOnline role pl...</td>\n",
       "      <td>He says that in the world of online gaming suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Articles  \\\n",
       "0     Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1     Dollar gains on Greenspan speechThe dollar has...   \n",
       "2     Yukos unit buyer faces loan claimThe owners of...   \n",
       "3     High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4     Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "...                                                 ...   \n",
       "2220  BT program to beat dialler scamsBT is introduc...   \n",
       "2221  Spam e-mails tempt net shoppersComputer users ...   \n",
       "2222  Be careful how you codeA new European directiv...   \n",
       "2223  US cyber security chief resignsThe man making ...   \n",
       "2224  Losing yourself in online gamingOnline role pl...   \n",
       "\n",
       "                                                Summary  \n",
       "0     TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1     The dollar has hit its highest level against t...  \n",
       "2     Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3     Rod Eddington, BA's chief executive, said the ...  \n",
       "4     Pernod has reduced the debt it took on to fund...  \n",
       "...                                                 ...  \n",
       "2220  BT is introducing two initiatives to help beat...  \n",
       "2221  A third of them read unsolicited junk e-mail a...  \n",
       "2222  This goes to the heart of the European project...  \n",
       "2223  Amit Yoran was director of the National Cyber ...  \n",
       "2224  He says that in the world of online gaming suc...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=df[['Articles','Summary']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Ascii Characters and null values from Articles and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scamsBT is introduc...</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppersComputer users ...</td>\n",
       "      <td>A third of them read unsolicited junk e-mail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you codeA new European directiv...</td>\n",
       "      <td>This goes to the heart of the European project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resignsThe man making ...</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gamingOnline role pl...</td>\n",
       "      <td>He says that in the world of online gaming suc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Articles  \\\n",
       "0     Ad sales boost Time Warner profitQuarterly pro...   \n",
       "1     Dollar gains on Greenspan speechThe dollar has...   \n",
       "2     Yukos unit buyer faces loan claimThe owners of...   \n",
       "3     High fuel prices hit BA's profitsBritish Airwa...   \n",
       "4     Pernod takeover talk lifts DomecqShares in UK ...   \n",
       "...                                                 ...   \n",
       "2220  BT program to beat dialler scamsBT is introduc...   \n",
       "2221  Spam e-mails tempt net shoppersComputer users ...   \n",
       "2222  Be careful how you codeA new European directiv...   \n",
       "2223  US cyber security chief resignsThe man making ...   \n",
       "2224  Losing yourself in online gamingOnline role pl...   \n",
       "\n",
       "                                                Summary  \n",
       "0     TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1     The dollar has hit its highest level against t...  \n",
       "2     Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3     Rod Eddington, BA's chief executive, said the ...  \n",
       "4     Pernod has reduced the debt it took on to fund...  \n",
       "...                                                 ...  \n",
       "2220  BT is introducing two initiatives to help beat...  \n",
       "2221  A third of them read unsolicited junk e-mail a...  \n",
       "2222  This goes to the heart of the European project...  \n",
       "2223  Amit Yoran was director of the National Cyber ...  \n",
       "2224  He says that in the world of online gaming suc...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Articles']=df['Articles'].str.encode('ascii','ignore').str.decode('ascii')\n",
    "df['Summary']=df['Summary'].str.encode('ascii','ignore').str.decode('ascii')\n",
    "bbc_news=df\n",
    "bbc_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "bbc_news.to_csv(\"bbc_news.csv\", index=False)  # index=False to avoid adding row numbers\n",
    "print(\"CSV file saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstractive Summarization (Using BART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Articles  \\\n",
      "0  Ad sales boost Time Warner profitQuarterly pro...   \n",
      "1  Dollar gains on Greenspan speechThe dollar has...   \n",
      "2  Yukos unit buyer faces loan claimThe owners of...   \n",
      "3  High fuel prices hit BA's profitsBritish Airwa...   \n",
      "4  Pernod takeover talk lifts DomecqShares in UK ...   \n",
      "\n",
      "                                             Summary  \n",
      "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
      "1  The dollar has hit its highest level against t...  \n",
      "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
      "3  Rod Eddington, BA's chief executive, said the ...  \n",
      "4  Pernod has reduced the debt it took on to fund...  \n",
      "Articles    0\n",
      "Summary     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"bbc_news.csv\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Articles  2225 non-null   object\n",
      " 1   Summary   2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"Articles\"])  # Remove rows with missing articles\n",
    "df = df[df[\"Articles\"].str.strip() != \"\"]  # Remove empty articles\n",
    "\n",
    "# Show dataset info after cleaning\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sumy in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (2.32.3)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (3.9.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\nirma\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Articles  \\\n",
      "0  Ad sales boost Time Warner profitQuarterly pro...   \n",
      "1  Dollar gains on Greenspan speechThe dollar has...   \n",
      "2  Yukos unit buyer faces loan claimThe owners of...   \n",
      "3  High fuel prices hit BA's profitsBritish Airwa...   \n",
      "4  Pernod takeover talk lifts DomecqShares in UK ...   \n",
      "\n",
      "                                  Extractive_Summary  \n",
      "0  Ad sales boost Time Warner profitQuarterly pro...  \n",
      "1  Dollar gains on Greenspan speechThe dollar has...  \n",
      "2  Yukos unit buyer faces loan claimThe owners of...  \n",
      "3  High fuel prices hit BA's profitsBritish Airwa...  \n",
      "4  Pernod takeover talk lifts DomecqShares in UK ...  \n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Function for extractive summarization\n",
    "def extractive_summary(text, sentence_count=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# Apply Extractive Summarization\n",
    "df[\"Extractive_Summary\"] = df[\"Articles\"].apply(lambda x: extractive_summary(x))\n",
    "\n",
    "# Check results\n",
    "print(df[[\"Articles\", \"Extractive_Summary\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Load BBC Dataset\n",
    "df = pd.read_csv(\"bbc_news.csv\")\n",
    "\n",
    "# ✅ Check for missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ✅ Split dataset into training (80%) & testing (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Load Pretrained Abstractive Summarization Model (BART)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# ✅ Abstractive Summarization Function\n",
    "def abstractive_summary(text, max_input=1024, min_output=50, max_output=150):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_input, truncation=True).to(device)\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_output,\n",
    "        min_length=min_output,\n",
    "        num_beams=4,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# ✅ Extractive Summarization Function (TextRank)\n",
    "def extractive_summary(text, sentence_count=3):\n",
    "    parser = PlaintextParser.from_string(str(text), Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    return \" \".join(str(sentence) for sentence in summary)\n",
    "\n",
    "# ✅ Apply Summarization on Test Data\n",
    "test_df[\"Abstractive_Summary\"] = test_df[\"Articles\"].apply(lambda x: abstractive_summary(x))\n",
    "test_df[\"Extractive_Summary\"] = test_df[\"Articles\"].apply(lambda x: extractive_summary(x))\n",
    "\n",
    "# ✅ Show Results\n",
    "print(test_df[[\"Articles\", \"Abstractive_Summary\", \"Extractive_Summary\"]].head())\n",
    "\n",
    "# ✅ Save Summaries to CSV\n",
    "test_df.to_csv(\"bbc_summarized.csv\", index=False)\n",
    "print(\"Summarized dataset saved as 'bbc_summarized.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
